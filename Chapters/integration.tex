\chapter{Integration}
\label{chap_Integration}
This chapter provides an in-depth explanation of how the described methods were implemented into the larger XGEE codebase.

\section{System Overview and Workflow}
\colorbox{lightgray}{%
  \parbox{\dimexpr\linewidth-2\fboxsep}{%
  "XGEE is a web-based graphical model editor that leverages an editor model to define editors for ecore models in a model-driven way, facilitating both visualization and interaction. The editor model allows defining editors for ecore models in a model-driven way. Both visualization and interaction are modeled" \cite{og_paper}%
  }%
}

XGEE's visualization verification is implemented as a modification to the main editor.\\
For the verification process to function correctly, a screenshot of the entire screen is preprocessed to isolate the relevant portions of XGEE's editor window by removing elements like the browser UI and background grid. During the tokenization step, the positions, dimenstions and contents of edges, vertices, and text are detected and stored. This data is subsequently used in the syntactical analysis to identify inconsistencies in parent-child relationships between tokens. A new model is then instantiated based on the detected tokens and the visualization model. This model is compared to the original, and any discrepancies are highlighted through both graphical and textual user interfaces.\\
Edge, vertex, and text detections occur during the tokenization phase of the verification pipeline. In the original integration, each detection algorithm was implemented as a class within the \textit{detector.py} file, while their execution was managed by the \textit{diagram\_tokenization\_orchestrator.py} file, which determined the order and process of the tokenization. This structure is retained and extended in the new implementation.

\section{Edge Detection Integration}
In the context of XGEE, implementing a new edge detection algorithm was a straightforward process due to the compatibility of input and output formats. However, the integration was still important for keeping the system modular and scalable.\\
To implement the new functionality, the algorithm is divided into sections, each expressed as an independend function. These functions are appended to the edge detection class, maintaining modularity and readability. By ensuring the edge detection operates with the same input (screenshots) and provides the same output (OpenCV polylines) as the original method, integrating the new functions into the edge detection pipeline became straightforward.
The \textit{diagram\_tokenization\_orchestrator} queries information such as the stroke width and color from the editor model, which could be used in the future to further generalize the edge detection. It also instantiates an object of the edge detection class, passing the workspace path as an argument to extract data like the intersection template. The polylines are stored using a dedicated data storage function, ensuring subsequent steps proceed smoothly without requiering additional integration effort.

\section{Vertex Detection Integration}
The implementation of a new vertex detection algorithm into XGEE's codebase proved significantly more complex than edge detection due to the order-dependend execution of the methods and the need for functions to dynamically share and modify input data during runtime.\\
Previously, a list of vertices for the current editor generated by the \textit{diagram\_tokenization\_orchestrator} drove the vertex detection process. The method iterated through this list, performing detection cycles for each vertex type, distinguishing between scalable and non-scalable vertices. However, this static approach proved inadequate in the allocations editor due to overlapping vertices, where detecting the top-level vertex first becomes critical. Furthermore, it was not possible for functions to pass intermediate results, such as detected subtasks, to subsequent functions. This was because the input (a preprocessed screenshot) was initialized at the start of the verification process using the \textit{ImageWrapper} class and remained static throughout.\\
To solve these issues, the new implementation preprocesses the list of editor vertices to ensure vertex detection in the correct hierarchical order and introduces a way for input images to be updated dynamically during runtime.

In the new implementation, the \textit{diagram\_tokenization\_orchestrator} queries vertex attributes such as the filepath, shape, positioning within other vertices and the parent's filepath from the editor model domain. The vertex's position within the list of editor vertices is determined by the presence of the \textit{isPositioningBody} attribute: vertices with this attribute are classified as subvertices, while those without it are considered top-level vertices. Subvertices need to be detected first, as their overlap with parent vertices would otherwise interfere with the reliable detection of those parent vertices.\\
Using these attributes, the list of editor vertices is first sorted, prioritizing subtasks. The \textit{diagram\_tokenization\_orchestrator} then iterates through the sorted list, performing vertex detection for each vertex type. 
To enable the vertex detection function to alter the input of all subsequent iterations of the function, the creation of the \textit{ImageWrapper} object is shifted inside the vertex detection loop. This ensures a new \textit{ImageWrapper} instance in instantiated for every iteration, using the updated image.\\
For subvertices, a new function overlays the detected bounding boxes in the target image with the parent vertex's main color (e.g., the gray of device vertices). The altered image is then used to instantiate the ImageWrapper, ensuring subsequent stages of vertex detection and verification operate on the updated input. This iterative approach enables precise detection of both subvertices and their parent vertices while simplifying the image progressively.
After all subvertices are processed, almost all remaining vertices can be detected using the methods described in \ref{chp_vertex_detection}, as the subvertices no longer interfere with the detection process.\\
An alternative approach for resolving overlapping vertices described in \ref{chp_edge_detection} has been implemented for signal container detection in the allocations editor, facilitating the need to process signal containers seperately using a distinct detection class and seperating them from the other vertices using the \textit{filepath} attribute.\\
Because container vertices are non-scalable, the newly created \textit{ContainerDetector} class inherits from the existing \textit{PortDetector} class. This inheritance allows the \textit{ContainerDetector} to reutilize the majority of the functionality provided by \textit{PortDetector}, while overriding the \textit{detect\_vertices} function to implement a specialized detection process tailored to container vertices.\\
Depending on the vertex type, an object of either \textit{ScalableVertexDetector}, \textit{ContainerDetector} or \textit{PortDetector} is instantiated and used to detect the vertices.\\
The detected vertices are stored using a dedicated data storage function, ensuring subsequent steps proceed smoothly without requiring additional integration effort.

\section{Text Recognition Integration}
The integration of EasyOCR into the XGEE codebase was straightforward due to the simplicity of the EasyOCR API. The library was imported into the \textit{diagram\_tokenization\_orchestrator} module, and the \textit{detect\_text} function was modified to use EasyOCR for extracting text from the preprocessed images. The extracted text was stored using the existing dedicated data storage function, allowing subsequent processing steps to operate without additional modifications.\\
A challenge was encountered with the bounding box dimensions provided by EasyOCR: Unlike PyTesseract, EasyOCR includes padding around detected text regions, resulting in less precise positional data. This difference caused inconsistencies in positional accuracy and introduced errors in downstream model comparison methods. To ensure compatibility with the existing codebase, the dimensions of the bounding boxes were adjusted to more closely match those of PyTesseract.

\section{Testing and Validation of the Integration}
To test the Methods, the XGEE environment was used to create models with a known structure, incorporating different testcases in different editors. The model was processed by the verification pipeline. If neccecary, text, vertex or edge detections could be turned off to accelerate testing and reduce the workload when evaluating newly implemented methods. The results were compared to the expected output, and any discrepancies were analyzed to identify the cause. To further sstreamline the testing process, all previously mentioned methods logged intermediate images and results using a dedicated python logging package. This simplified the process of identifiying and resolving new issues.

To classify the performance of all newly implemented methods, ten testcases in each editor were processed and analyzed to demonstrate the functionality and limitations of the new additions. These evaluations are presented in Chapter \ref{chap_evaluation}.